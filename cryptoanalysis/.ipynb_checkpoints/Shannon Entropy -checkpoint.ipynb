{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shannon Entropy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to calculate shannon entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shannon_entropy(sequence):\n",
    "    dict = {}\n",
    "    length = len(sequence)\n",
    "    for c in sequence:\n",
    "        if c in dict:\n",
    "            current_number = dict.get(c)\n",
    "            dict[c] = current_number + 1\n",
    "        else:\n",
    "            dict[c] = 1\n",
    "    probabilities = {k: float(v)/length for (k,v) in dict.items()}\n",
    "    print(probabilities)\n",
    "    shannon_entropy = 0\n",
    "    for character, probability in probabilities.items():\n",
    "        shannon_entropy = shannon_entropy + (probability * math.log2(probability))\n",
    "\n",
    "    shannon_entropy = shannon_entropy * -1\n",
    "    return shannon_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------------------\n",
      "{'C': 0.16507936507936508, 'T': 0.3111111111111111, 'G': 0.1523809523809524, 'N': 0.02857142857142857, 'A': 0.34285714285714286}\n",
      "for sequence 1 shannon entropy is: 2.0427006998225865\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "{'G': 0.2020460358056266, 'T': 0.4040920716112532, 'C': 0.16879795396419436, 'A': 0.20460358056265984, 'N': 0.020460358056265986}\n",
      "for sequence 2 shannon entropy is: 2.010819434681725\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "{'A': 0.4, 'C': 0.15555555555555556, 'G': 0.16, 'T': 0.27555555555555555, 'N': 0.008888888888888889}\n",
      "for sequence 3 shannon entropy is: 1.9423627220674633\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "{'C': 0.24091778202676864, 'G': 0.19120458891013384, 'A': 0.3422562141491396, 'T': 0.22562141491395793}\n",
      "for sequence 4 shannon entropy is: 1.9651264224927136\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "{'A': 0.3514056224899598, 'C': 0.21485943775100402, 'T': 0.25903614457831325, 'G': 0.1746987951807229}\n",
      "for sequence 5 shannon entropy is: 1.9514009035459536\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "{'C': 0.16608996539792387, 'G': 0.17647058823529413, 'T': 0.3304498269896194, 'A': 0.32698961937716264}\n",
      "for sequence 6 shannon entropy is: 1.9270078463710347\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "{'G': 0.21390300720033883, 'T': 0.2805167301990682, 'C': 0.2175137653536637, 'A': 0.2880664972469293}\n",
      "for sequence 7 shannon entropy is: 1.9862911118293898\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "{'G': 0.21755429597620518, 'A': 0.28294517088501037, 'T': 0.2837308490936641, 'C': 0.21576968404512037}\n",
      "for sequence 8 shannon entropy is: 1.987128066623325\n",
      "-----------------------------------------------------------\n",
      "-----------------------------------------------------------\n",
      "{'G': 0.24055135615829257, 'A': 0.2810137839039573, 'C': 0.27523343708314807, 'T': 0.20320142285460205}\n",
      "for sequence 9 shannon entropy is: 1.9885382930106297\n",
      "-----------------------------------------------------------\n",
      "//////////////////////////////////////////////////////////////////////////////////\n",
      "//////////////////////////////////////////////////////////////////////////////////\n",
      "Calculating entropy for the hotbits binary file\n",
      "reading hotfile\n",
      "{168: 0.00341796875, 83: 0.005859375, 64: 0.00390625, 183: 0.00341796875, 52: 0.0029296875, 53: 0.00537109375, 229: 0.00341796875, 186: 0.00341796875, 101: 0.00537109375, 128: 0.00439453125, 72: 0.00732421875, 108: 0.00390625, 84: 0.0029296875, 222: 0.00537109375, 42: 0.0048828125, 156: 0.00439453125, 245: 0.00439453125, 120: 0.00341796875, 31: 0.0029296875, 67: 0.00390625, 189: 0.0029296875, 1: 0.00390625, 15: 0.00390625, 208: 0.00439453125, 74: 0.0029296875, 23: 0.005859375, 210: 0.0048828125, 141: 0.00341796875, 236: 0.0068359375, 43: 0.005859375, 145: 0.00732421875, 89: 0.00390625, 126: 0.001953125, 175: 0.0029296875, 51: 0.00244140625, 63: 0.0048828125, 85: 0.001953125, 33: 0.00390625, 255: 0.00390625, 114: 0.00537109375, 162: 0.00439453125, 205: 0.0048828125, 249: 0.00390625, 178: 0.00390625, 239: 0.0029296875, 123: 0.001953125, 112: 0.00341796875, 225: 0.0068359375, 10: 0.00244140625, 61: 0.00634765625, 217: 0.0068359375, 232: 0.00390625, 71: 0.00537109375, 94: 0.005859375, 184: 0.00439453125, 235: 0.00390625, 25: 0.00537109375, 140: 0.00537109375, 223: 0.005859375, 115: 0.0029296875, 209: 0.00244140625, 111: 0.00634765625, 185: 0.0029296875, 20: 0.00537109375, 104: 0.00537109375, 103: 0.00634765625, 49: 0.0048828125, 27: 0.00537109375, 93: 0.00146484375, 211: 0.0068359375, 57: 0.00390625, 17: 0.0078125, 207: 0.00244140625, 146: 0.00439453125, 188: 0.00244140625, 92: 0.00537109375, 117: 0.0029296875, 159: 0.00146484375, 100: 0.00341796875, 193: 0.00439453125, 242: 0.0029296875, 246: 0.0048828125, 54: 0.00341796875, 134: 0.00244140625, 113: 0.005859375, 174: 0.00244140625, 105: 0.00390625, 133: 0.00341796875, 29: 0.00341796875, 204: 0.00439453125, 197: 0.005859375, 137: 0.0029296875, 44: 0.0048828125, 173: 0.00341796875, 48: 0.00390625, 81: 0.00390625, 153: 0.00390625, 155: 0.00732421875, 250: 0.00390625, 109: 0.00439453125, 5: 0.00244140625, 213: 0.0048828125, 157: 0.00341796875, 11: 0.00244140625, 226: 0.00341796875, 144: 0.00439453125, 192: 0.00390625, 65: 0.00341796875, 160: 0.00390625, 164: 0.00390625, 191: 0.00390625, 171: 0.00537109375, 149: 0.00537109375, 91: 0.00537109375, 119: 0.00439453125, 80: 0.0068359375, 87: 0.00439453125, 169: 0.001953125, 124: 0.00537109375, 106: 0.00390625, 150: 0.0048828125, 21: 0.00341796875, 45: 0.0029296875, 206: 0.00341796875, 165: 0.00341796875, 138: 0.00537109375, 238: 0.0048828125, 97: 0.00537109375, 187: 0.00537109375, 68: 0.0048828125, 116: 0.00390625, 75: 0.0048828125, 196: 0.0048828125, 139: 0.00390625, 172: 0.00341796875, 35: 0.00390625, 253: 0.00439453125, 30: 0.00244140625, 3: 0.00244140625, 58: 0.0048828125, 182: 0.00390625, 37: 0.0029296875, 98: 0.001953125, 190: 0.0048828125, 36: 0.00634765625, 32: 0.00341796875, 28: 0.0048828125, 86: 0.00390625, 16: 0.00439453125, 46: 0.0048828125, 212: 0.00341796875, 220: 0.0048828125, 234: 0.0048828125, 230: 0.0029296875, 244: 0.00439453125, 216: 0.0048828125, 19: 0.00634765625, 2: 0.00439453125, 41: 0.00341796875, 130: 0.0048828125, 131: 0.00390625, 179: 0.00439453125, 34: 0.00244140625, 201: 0.0048828125, 24: 0.0029296875, 195: 0.00537109375, 40: 0.00341796875, 14: 0.00146484375, 22: 0.00439453125, 121: 0.00439453125, 247: 0.00439453125, 118: 0.005859375, 96: 0.00244140625, 76: 0.00244140625, 90: 0.00341796875, 77: 0.00439453125, 129: 0.00634765625, 50: 0.00341796875, 73: 0.00439453125, 4: 0.00341796875, 221: 0.0048828125, 152: 0.00537109375, 0: 0.00390625, 224: 0.00390625, 163: 0.0048828125, 70: 0.00341796875, 9: 0.00537109375, 55: 0.0029296875, 8: 0.00341796875, 122: 0.0048828125, 251: 0.00341796875, 38: 0.00244140625, 228: 0.00439453125, 161: 0.00244140625, 241: 0.00244140625, 218: 0.00341796875, 198: 0.00439453125, 194: 0.001953125, 148: 0.00244140625, 219: 0.00537109375, 125: 0.0029296875, 227: 0.00244140625, 78: 0.00341796875, 158: 0.00244140625, 254: 0.001953125, 252: 0.001953125, 248: 0.00341796875, 102: 0.00732421875, 200: 0.00146484375, 13: 0.001953125, 136: 0.00341796875, 135: 0.00244140625, 6: 0.00244140625, 181: 0.0048828125, 79: 0.00244140625, 82: 0.0029296875, 243: 0.00244140625, 214: 0.0009765625, 26: 0.005859375, 132: 0.00439453125, 59: 0.0048828125, 215: 0.0029296875, 154: 0.0048828125, 233: 0.0029296875, 142: 0.00146484375, 203: 0.0048828125, 39: 0.005859375, 66: 0.0029296875, 12: 0.00146484375, 170: 0.001953125, 147: 0.00244140625, 240: 0.00244140625, 231: 0.00390625, 95: 0.005859375, 127: 0.0029296875, 62: 0.00244140625, 7: 0.00244140625, 167: 0.00244140625, 99: 0.00244140625, 47: 0.0029296875, 60: 0.00341796875, 88: 0.0029296875, 166: 0.00244140625, 176: 0.00341796875, 110: 0.00244140625, 237: 0.00341796875, 202: 0.00439453125, 180: 0.0029296875, 69: 0.0029296875, 199: 0.00244140625, 18: 0.0029296875, 56: 0.00146484375, 107: 0.00341796875, 143: 0.00048828125, 151: 0.0009765625, 177: 0.00146484375}\n",
      "shannon entropy for Hotbits bitnary file is : 7.908131414269236\n",
      "//////////////////////////////////////////////////////////////////////////////////\n",
      "Calculating entropy for an aes-256 encryted file\n",
      "{83: 0.0125, 97: 0.0125, 108: 0.0125, 116: 0.0125, 101: 0.0125, 100: 0.0125, 95: 0.025, 73: 0.0125, 183: 0.025, 242: 0.0125, 228: 0.0125, 163: 0.0125, 23: 0.0125, 89: 0.0125, 51: 0.0125, 196: 0.0125, 238: 0.025, 2: 0.0125, 18: 0.0125, 151: 0.0125, 68: 0.0125, 226: 0.0125, 40: 0.0125, 244: 0.0125, 61: 0.0125, 138: 0.0125, 33: 0.0125, 124: 0.0125, 5: 0.0125, 252: 0.0125, 255: 0.025, 173: 0.0125, 213: 0.0125, 56: 0.0125, 146: 0.025, 136: 0.0125, 202: 0.0125, 7: 0.0125, 145: 0.0125, 206: 0.0125, 105: 0.0125, 32: 0.0375, 104: 0.0125, 17: 0.0125, 3: 0.025, 55: 0.0125, 34: 0.0125, 248: 0.0125, 160: 0.025, 230: 0.0125, 221: 0.0125, 6: 0.0125, 63: 0.0125, 98: 0.0125, 46: 0.0125, 102: 0.0125, 31: 0.0125, 125: 0.0125, 209: 0.0125, 199: 0.0125, 181: 0.0125, 25: 0.0125, 203: 0.0125, 120: 0.0125, 65: 0.0125, 234: 0.0125, 186: 0.0125, 92: 0.0125, 237: 0.0125, 4: 0.0125, 232: 0.0125}\n",
      "shannon entropy for aes-256 encryted file is : 6.087492001110315\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,10):\n",
    "    print(\"-----------------------------------------------------------\")\n",
    "    sequence_location = \"./adn_sequences/seq\" + str(i)\n",
    "    with open(sequence_location, 'r') as f:\n",
    "        read_data = f.read()\n",
    "    f.closed\n",
    "    clean_sequence = read_data.replace(\" \", \"\").replace(\"\\n\", \"\")\n",
    "    se = shannon_entropy(clean_sequence)\n",
    "    print(\"for sequence \" + str(i) + \" shannon entropy is: \" + str(se))\n",
    "    print(\"-----------------------------------------------------------\")\n",
    "\n",
    "print(\"//////////////////////////////////////////////////////////////////////////////////\")\n",
    "print(\"//////////////////////////////////////////////////////////////////////////////////\")\n",
    "print(\"Calculating entropy for the hotbits binary file\")\n",
    "with open(\"./Hotbits.api\", 'rb') as file:\n",
    "        print(\"reading hotfile\")\n",
    "        read_data = file.read()\n",
    "file.closed\n",
    "shannon_bits = shannon_entropy(read_data)\n",
    "print(\"shannon entropy for Hotbits bitnary file is : \" + str(shannon_bits) )\n",
    "print(\"//////////////////////////////////////////////////////////////////////////////////\")\n",
    "print(\"Calculating entropy for an small aes-256 encryted file\")\n",
    "with open(\"./file.enc\", 'rb') as file:\n",
    "        read_data = file.read()\n",
    "file.closed\n",
    "shannon_bits = shannon_entropy(read_data)\n",
    "print(\"shannon entropy for small aes-256 encryted file is : \" + str(shannon_bits) )\n",
    "print(\"//////////////////////////////////////////////////////////////////////////////////\")\n",
    "print(\"Calculating entropy for an large aes-256 encryted file\")\n",
    "with open(\"./enc2.enc\", 'rb') as file:\n",
    "        read_data = file.read()\n",
    "file.closed\n",
    "shannon_bits = shannon_entropy(read_data)\n",
    "print(\"shannon entropy for large aes-256 encryted file is : \" + str(shannon_bits) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-7.96875\n"
     ]
    }
   ],
   "source": [
    "test = 0\n",
    "for i in range(1,256):\n",
    "    test =  test + (float(1/256) * math.log2(1/256))\n",
    "\n",
    "print(str(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
